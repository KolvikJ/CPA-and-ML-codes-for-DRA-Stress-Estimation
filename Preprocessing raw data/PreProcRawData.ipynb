{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a264ee91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestNr1 already exists. Skipping.\n",
      "testNr2 already exists. Skipping.\n",
      "testNr3 already exists. Skipping.\n",
      "testNr4 already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# User-defined Configuration\n",
    "# ----------------------------\n",
    "# Input the filename for the CSV file containing raw data in the required format\n",
    "rawFilename = \"rawDataFilename\"    #Do not include \".csv\"\n",
    "\n",
    "# Input the filename for the CSV file the preprocessed data is to be stored to\n",
    "procFilename = \"preprocessedDataFilename\"    #Do not include \".csv\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Preprocessing Functions\n",
    "# ----------------------------\n",
    "# Function preprocessing raw data\n",
    "def process_experiments(raw_filename, proc_filename):\n",
    "    \"\"\"\n",
    "    Reads raw CSV, processes each experiment group (6 columns), and stores results.\n",
    "    \n",
    "    Parameters:\n",
    "    - raw_filename: Name of the CSV file containing raw data\n",
    "    - cpa_filename: Name of the CSV file the processed data is going to be stored\n",
    "    \"\"\"\n",
    "    delim = detect_delimiter(f\"{raw_filename}.csv\")\n",
    "    df = pd.read_csv(f\"{raw_filename}.csv\", sep=delim)\n",
    "    cols = list(df.columns)\n",
    "    total_cols = len(cols)\n",
    "    \n",
    "    if total_cols % 6 != 0:\n",
    "        raise ValueError(\"Raw data must have columns multiple of 6\")\n",
    "\n",
    "    num_experiments = total_cols // 6\n",
    "    for idx in range(num_experiments):\n",
    "        base = idx * 6\n",
    "        dataTag = cols[base]\n",
    "        # parse preLoad, keep as string if not numeric\n",
    "        try:\n",
    "            preLoad = float(cols[base + 1])\n",
    "        except ValueError:\n",
    "            preLoad = cols[base + 1]\n",
    "\n",
    "        # extract and clean data arrays\n",
    "        x0 = df[cols[base + 2]].dropna().values\n",
    "        y0 = df[cols[base + 3]].dropna().values\n",
    "        x1 = df[cols[base + 4]].dropna().values\n",
    "        y1 = df[cols[base + 5]].dropna().values\n",
    "\n",
    "        # align lengths by interpolating the longer onto the shorter\n",
    "        if len(x0) >= len(x1):\n",
    "            base_x, base_y1 = x1, y1\n",
    "            f0 = interp1d(x0, y0, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            y0i = f0(base_x)\n",
    "            y_diff = base_y1 - y0i\n",
    "        else:\n",
    "            base_x, base_y0 = x0, y0\n",
    "            f1 = interp1d(x1, y1, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            y1i = f1(base_x)\n",
    "            y_diff = y1i - base_y0\n",
    "\n",
    "        # store processed results\n",
    "        storeANNDataCSV(base_x, y_diff, proc_filename, dataTag, preLoad)\n",
    "    return\n",
    "\n",
    "\n",
    "# Function storing processed data in a CSV file in required format\n",
    "def storeANNDataCSV(x_stress, y_straindiff, filename, dataTag, preLoad):\n",
    "    \"\"\"\n",
    "    Stores processed data into a CSV file with header 'dataTag,preLoad,xy1,...,xy150'.\n",
    "    Interpolates y_straindiff onto 150 equally spaced stress points and computes xy_energy.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataTag: Unique identifier for the DRA experiment.\n",
    "    - x_stress: List or array of x-axis values representing stress.\n",
    "    - y_straindiff: List or array of y-axis values representing strain difference.\n",
    "    - preLoad: Pre-load value associated with the DRA experiment.\n",
    "    - filename: Name of the CSV file the preprocessed data is stored.\n",
    "    \"\"\"\n",
    "    filepath = f\"{filename}.csv\"\n",
    "    # Create file and header if not exists\n",
    "    if not os.path.exists(filepath):\n",
    "        with open(filepath, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            header = [\"dataTag\", \"preLoad\"] + [f\"xy{i}\" for i in range(1,151)]\n",
    "            writer.writerow(header)\n",
    "    # Skip if already stored\n",
    "    if check_unique(filename, dataTag):\n",
    "        print(f\"{dataTag} already exists. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # New equally spaced x values\n",
    "    start_x, end_x = x_stress[0], x_stress[-1]\n",
    "    new_x = np.linspace(start_x, end_x, 150)\n",
    "    f = interp1d(x_stress, y_straindiff, kind='linear', fill_value=\"extrapolate\")\n",
    "    y_interp = f(new_x)\n",
    "\n",
    "    # Normalize and compute xy_energy\n",
    "    max_y = np.max(y_interp)\n",
    "    if max_y == 0:\n",
    "        y_norm = np.zeros_like(y_interp)\n",
    "    else:\n",
    "        y_norm = y_interp / max_y\n",
    "    xy_energy = new_x * y_norm\n",
    "\n",
    "    # Append row\n",
    "    row = [dataTag, preLoad] + list(xy_energy)\n",
    "    with open(filepath, \"a\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "    print(f\"{dataTag} added.\")\n",
    "    return\n",
    "\n",
    "    \n",
    "# Function which checks if an experiment has already been stored in the CSV file we are storing the processed data to.\n",
    "def check_unique(filename, dataTag):\n",
    "    \"\"\"\n",
    "    Check if an experiment with the same dataTag already exists in the processed CSV file.\n",
    "    \n",
    "     Parameters:\n",
    "    - dataTag: Unique identifier for the DRA experiment.\n",
    "    - filename: Name of the CSV file the preprocessed data is stored.\n",
    "    \"\"\"\n",
    "    filepath = f\"{filename}.csv\"\n",
    "    if not os.path.exists(filepath):\n",
    "        return False\n",
    "    with open(filepath, \"r\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader, None)\n",
    "        for row in reader:\n",
    "            if row and row[0] == dataTag:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Function which detects what delimiter is used in a CSV file\n",
    "def detect_delimiter(filename):\n",
    "    \"\"\"\n",
    "    Heuristic delimiter detection: count commas, semicolons, tabsâ€”\n",
    "    choose whichever appears most in the first 2Kb of the CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename: CSV file containing raw data.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', newline='') as f:\n",
    "        sample = f.read(2048)\n",
    "    counts = {\n",
    "        ',': sample.count(','),\n",
    "        ';': sample.count(';'),\n",
    "        '\\t': sample.count('\\t')\n",
    "    }\n",
    "    # pick the delimiter with the highest count; tie-break in favor of comma\n",
    "    delim = max(counts, key=lambda k: (counts[k], k == ','))\n",
    "    return delim\n",
    "\n",
    "\n",
    "\n",
    "# Running the algorithm\n",
    "process_experiments(rawFilename, procFilename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

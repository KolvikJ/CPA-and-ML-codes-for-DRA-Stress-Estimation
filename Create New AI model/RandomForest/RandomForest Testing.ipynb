{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ----------------------------\n",
    "# User-defined Configuration\n",
    "# ----------------------------\n",
    "# Input the name of Random Forest model which will be used for prediction\n",
    "model_name = \"ExampleModelName\"    #Do not include \".pkl\"\n",
    "\n",
    "# Input the name of the CSV file containing test data\n",
    "filename = \"testDataFile\"    #Do not include \".csv\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Load RandomForest Model\n",
    "# ----------------------------\n",
    "MODEL_FILE = f\"{model_name}.pkl\"\n",
    "with open(MODEL_FILE, \"rb\") as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "best_rf = model_data[\"model\"]\n",
    "scaler = model_data[\"scaler\"]\n",
    "PREDICTORS = model_data[\"predictors\"]\n",
    "TARGET = model_data[\"target\"]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Load and Preprocess Test Data\n",
    "# ----------------------------\n",
    "TEST_DATA_FILE = f\"{filename}.csv\"\n",
    "test_data = pd.read_csv(TEST_DATA_FILE)\n",
    "test_data = test_data.ffill()\n",
    "# Shuffle the test data (optional)\n",
    "test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Apply the saved scaler to the predictor columns.\n",
    "test_data[PREDICTORS] = scaler.transform(test_data[PREDICTORS])\n",
    "test_x = test_data[PREDICTORS]\n",
    "test_y = test_data[TARGET]\n",
    "data_tags = test_data[\"dataTag\"]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation Metrics\n",
    "# ----------------------------\n",
    "def regression_accuracy(actual, predicted):\n",
    "    \"\"\"\n",
    "    Compute regression accuracy as the mean of (min(actual, predicted)/max(actual, predicted))*100.\n",
    "    \"\"\"\n",
    "    accs = []\n",
    "    for a, p in zip(actual, predicted):\n",
    "        if a == 0 and p == 0:\n",
    "            acc = 100\n",
    "        elif a == 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            acc = (min(a, p) / max(a, p)) * 100\n",
    "        accs.append(acc)\n",
    "    return np.mean(accs)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Functions plotting results\n",
    "# ----------------------------\n",
    "def create_table(data_tags, preLoad, predicted, title=\"Model Predictions on Unseen Test Data\"):\n",
    "    \"\"\"\n",
    "    Creates and returns a styled table with columns: Index, Data Tag, Pre-load, and RF Predicted Stress.\n",
    "    \"\"\"\n",
    "    if not (len(data_tags) == len(preLoad) == len(predicted)):\n",
    "        raise ValueError(\"All input lists must have the same length.\")\n",
    "    indices = list(range(1, len(data_tags) + 1))\n",
    "    data_dict = {\n",
    "        \"Index\": indices,\n",
    "        \"Data Tag\": data_tags,\n",
    "        \"Pre-load\": preLoad,\n",
    "        \"RF Predicted Stress\": predicted,\n",
    "    }\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    styled_table = df.style.hide(axis=\"index\").set_caption(title).format({\n",
    "        \"Pre-load\": \"{:.2f}\",\n",
    "        \"RF Predicted Stress\": \"{:.2f}\"\n",
    "    })\n",
    "    return styled_table\n",
    "\n",
    "\n",
    "def plot_preLoad_vs_prediction(preLoad, predicted, title=\"Pre-load vs. RF Predicted Stress\"):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot of pre-load vs. RandomForest predicted stress and overlays an ideal y=x line.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(preLoad, predicted, color='blue', alpha=0.6, label='Data Points')\n",
    "    \n",
    "    # Create text annotations for each point.\n",
    "    texts = []\n",
    "    for p, a in zip(preLoad, predicted):\n",
    "        texts.append(plt.text(p, a, f'({p}, {round(a,2)})', fontsize=8, ha='left', va='bottom'))\n",
    "    adjust_text(texts, verbose=0)\n",
    "    \n",
    "    # Draw the y=x line.\n",
    "    min_val = min(min(preLoad), min(predicted))\n",
    "    max_val = max(max(preLoad), max(predicted))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Ideal: y = x')\n",
    "    \n",
    "    plt.xlabel(\"Pre-load [MPa]\")\n",
    "    plt.ylabel(\"RF Predicted Stress [MPa]\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Run Model on Test Data and Evaluate\n",
    "# ----------------------------\n",
    "test_preds = best_rf.predict(test_x)\n",
    "test_mse_val = mean_squared_error(test_y, test_preds)\n",
    "test_r2_val = r2_score(test_y, test_preds)\n",
    "test_reg_acc = regression_accuracy(test_y, test_preds)\n",
    "\n",
    "\n",
    "# Display evaluation metrics in a table\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Test MSE\", \"Test RÂ²\", \"Regression Accuracy\"],\n",
    "    \"Value\": [f\"{test_mse_val:.2f}\", f\"{test_r2_val:.2f}\", f\"{test_reg_acc:.2f}%\"]\n",
    "})\n",
    "print(\"Evaluation Metrics on Unseen Test Data:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Display pre-load vs. ANN predicted stress.\n",
    "table = create_table(data_tags, test_data[TARGET], test_preds, title=\"RandomForest Model Predictions on Test Data\")\n",
    "# The following display command works within Jupyter Notebook environments.\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(table)\n",
    "except ImportError:\n",
    "    print(table.data)  # For non-notebook environments, simply print the DataFrame.\n",
    "\n",
    "plot_preLoad_vs_prediction(test_data[TARGET].values, test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
